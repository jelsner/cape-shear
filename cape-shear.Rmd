---
title: "CAPE/SHEAR vs Cluster Characteristics"
author: "James Elsner"
output: html_document
editor_options: 
  chunk_output_type: console
---

Load packages.
```{r}
library(dplyr)
library(sf)
library(ggplot2)
library(lme4)
library(lubridate)
library(xtable)
```

Load the cluster-level tornado data.
```{r}
load("BigDays.RData")

BigDays.sfdfT <- BigDays.sfdfT %>%
  mutate(A = as.numeric(HullArea)/10^10,
         CAPE = maxCAPE/1000,
         CIN = minCIN/100,
         DLBS = maxBS_deep/10,
         SLBS = maxBS_shallow/10,
         P = totalPOP/100000, 
         M = maxMR/10)
dim(BigDays.sfdfT)
```

## Generate 4 figures of example clusters. 
```{r}
#Extract the big day using the unique ID created.
cluster1 <- BigDays.sfdfT %>%
  filter(ID == 19940719217)

#Generate a convex hull around the cluster.
cluster1 <- st_convex_hull(cluster1)

#Extract all tornadoes that are in the Day 1
cluster1torns <- All_Tornadoes %>%
  filter(ID == 19940719217)

cluster1torns$mag <- as.numeric(cluster1torns$mag)
cluster1torns$mag2 <- cut(cluster1torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
A <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster1) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.25, .2, .2, .2)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster1torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "July 19, 1994 \n 10 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
A  
```

```{r}
cluster2 <- BigDays.sfdfT %>%
  filter(ID == 199906061644)

cluster2 <- st_convex_hull(cluster2)

cluster2torns <- All_Tornadoes %>%
  filter(ID == 199906061644) 

cluster2 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)

cluster2torns$mag <- as.numeric(cluster2torns$mag)
cluster2torns$mag2 <- cut(cluster2torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
B <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster2) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .2, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.1, .1, .1, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster2torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "June 6, 1999 \n 36 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.15, 
              title.size = 1.5)
  B
```

```{r}
cluster3 <- BigDays.sfdfT %>%
  filter(ID == 200802053876)

cluster3 <- st_convex_hull(cluster3)

cluster3torns <- All_Tornadoes %>%
  filter(ID == 200802053876) 

cluster3 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)

cluster3torns$mag <- as.numeric(cluster3torns$mag)
cluster3torns$mag2 <- cut(cluster3torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
C <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster3) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.1, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster3torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "February 5, 2008 \n 85 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
C  
```

```{r}
#Extract the big day using the unique ID created. 
cluster4 <- BigDays.sfdfT %>%
  filter(ID == 201104274630)

#Generate a convex hull around the big day. 
cluster4 <- st_convex_hull(cluster4)

#Extract all tornadoes that are in the biggestday 
cluster4torns <- All_Tornadoes %>%
  filter(ID == 201104274630) 

cluster4torns$mag <- as.numeric(cluster4torns$mag)
cluster4torns$mag2 <- cut(cluster4torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
D <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster4) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.15, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster4torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "April 27, 2011 \n 173 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
  
D
```

```{r}
tmap_arrange(A, B, C, D)
```
`Figure 1: ` \label{fig:Clusters}

## Cluster statistics by time of day
```{r}
BigDays.sfdfT %>%
  group_by(NARRZtime) %>%
  summarize(clusnum = n(), 
            numtorn = sum(nT),
            tornperclus = numtorn/clusnum,
            avgdur = mean(Duration)/3600)
```

## Distribution of casualties
```{r}
BigDays.sfdfT %>%
  st_drop_geometry() %>%
  group_by(GroupDayCas) %>%
  summarize(nC = n(),
            pC = nC/nrow(BigDays.sfdfT)) %>%
  arrange(desc(nC))
```

## How are casualties changing annually?
```{r}
x <- BigDays.sfdfT %>%
  group_by(Year) %>%
  summarize(totclus = n(), 
            avgcas = (mean(GroupDayCas)/totclus),
            totcas = (sum(GroupDayCas)/totclus))

a <- ggplot(x, (aes(x = Year, y = avgcas))) +
  geom_line(color = "black", lwd = 1) +
  geom_smooth(method = lm) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1994,2018,1))) +
  theme_bw() +
  xlab("Year") +
  ylab("Average Casualties per Cluster\n ") 

a + theme(axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14))
```

*Separate the clusters by week of the year.*
```{r}
TornsbyWeek <- BigDays.sfdfT %>% 
  group_by(week = week(cDate)) %>%
  summarize(totalclusters = n(),
            numtorn = sum(nT),
            avgsize = numtorn / totalclusters,
            tornrate = mean(TorPerHour), 
            torndens = mean(TorPerKm), 
            avgarea = mean(HullArea * (10^-6)), 
            avgcas = mean(GroupDayCas),
            avgcasperkm = mean((GroupDayCas/((totalPOP+1)/1000000))))
```

**For each week sum the number of clusters and divide by the number of years to get the rate lambda. Then take 1-dpois(lambda) * 100 to get the probability**

## Empirical Probability of getting a cluster by week`
```{r}
Years <- 2018-1994 + 1

lambdas <- TornsbyWeek$totalclusters / Years
probs <- (1 - dpois(0, lambdas)) * 100

TornsbyWeek <- cbind(TornsbyWeek, probs)
```

```{r}
x.Date <- as.Date(paste(rep(1994:2018, each = 12), rep(1:12, 2), 1, sep = "-"))
library(zoo)
x <- zoo(rnorm(24), x.Date)
times <- time(x)
ticks <- as.data.frame(x = seq(times[1], times[length(times)], by = "weeks"))

week <- as.data.frame(ticks[1:53,])
  
months <- as.data.frame(format(week, "%b"))
Mo <- as.data.frame(format(week, "%m"))
day <- as.data.frame(format(week, "%d"))

dat <- as.data.frame(cbind(week, Mo, months, day))
colnames(dat) <- c("Week", "Mo", "Month", "Day") 

dat <- dat %>%
  group_by(Month, Day, Mo) %>%
  summarize(count = n(),
            Week = paste0(Month, " ", Day))


dat <- dat[order(dat$Mo),]

labels = dat$Week
```

```{r}
A <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = probs/100), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = probs/100), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  scale_y_continuous(limits = c(0, 1)) + 
#  geom_smooth(aes(x = week, y = probs/100), span = .5, se = FALSE, color = "gray70", size = 1) +
  theme_bw() +
  xlab("") +
  ylab("Probability of a cluster\n ")

A <- A + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("A")
```

```{r}
B <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = avgsize), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = avgsize), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  scale_y_continuous(breaks = c(seq(0,50,10)), limits = c(0, 50)) + 
  theme_bw() +
  xlab("") +
  ylab("Number of tornadoes\n ")

B <- B + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("B")
```

```{r}
C <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = as.numeric(avgcasperkm)), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = as.numeric(avgcasperkm)), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  #scale_y_continuous(breaks = c(seq(0,150,25)), limits = c(0, 150)) + 
  theme_bw() +
  xlab("") +
  ylab("Number of casualties\n")

C <- C + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("C")
C
```

## Combine into one figure
```{r}
ggarrange(A, B, C, ncol = 1)
```

## Get the maximum, minimum, and average of the environmental variables. Create a table displaying this information.
```{r}
maximum <- as.matrix(c(max(BigDays.sfdfT$maxCAPE), max(BigDays.sfdfT$maxVSTM), max(BigDays.sfdfT$maxBS_deep), max(BigDays.sfdfT$maxBS_shallow), max(BigDays.sfdfT$maxHLCY), (max(BigDays.sfdfT$HullArea)*1e-6), max(BigDays.sfdfT$minCIN), max(BigDays.sfdfT$maxUSTM)), ncol = 1)

minimum <- as.matrix(c(min(BigDays.sfdfT$maxCAPE), min(BigDays.sfdfT$maxVSTM), min(BigDays.sfdfT$maxBS_deep), min(BigDays.sfdfT$maxBS_shallow), min(BigDays.sfdfT$maxHLCY), (min(BigDays.sfdfT$HullArea)*1e-6), min(BigDays.sfdfT$minCIN), min(BigDays.sfdfT$maxUSTM)), ncol = 1)

average <- as.matrix(c(mean(BigDays.sfdfT$maxCAPE), mean(BigDays.sfdfT$maxVSTM), mean(BigDays.sfdfT$maxBS_deep), mean(BigDays.sfdfT$maxBS_shallow), mean(BigDays.sfdfT$maxHLCY), (mean(BigDays.sfdfT$HullArea)*1e-6), mean(BigDays.sfdfT$minCIN), mean(BigDays.sfdfT$maxUSTM)), ncol = 1)

Variable <- as.matrix(c("Convective Available Potential Energy", "Northward Storm Motion", "Deep-Layer Bulk Shear", "Shallow-Layer Bulk Shear", "Helicity", "Outbreak Area", "CIN", "Eastward Storm Motion"), ncol = 1)

abbr <- as.matrix(c("CAPE", "VSTM", "DLBS","SLBS", "HLCY", "AREA", "CIN", "USTM"), ncol = 1)

env_variation <- cbind(Variable, abbr, maximum, minimum, average)
colnames(env_variation) <- c("Variable Name", "Abbreviation", "Maximum", "Minimum", "Average")

xtable(as.data.frame((env_variation))) #round to sig fig
```
`Table 2: The range and average highest (lowest for CIN) value of the environmental variables across the 767 tornado clusters used in the study.` \label{tab:VarValues}

## Tornado count model

Consider only CAPE, CIN, BS (deep & shallow)
```{r}
library(MASS)

modelInitial <- glm.nb(nT ~ A + Lat + Lon + Year + CAPE + CIN + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelInitial)

modelInitialPoisson <- glm(nT ~ A + Lat + Lon + CAPE + CIN + DLBS + SLBS, family = "poisson", data = BigDays.sfdfT)
summary(modelInitialPoisson)

modelFinal <- glm.nb(nT ~ A + CAPE + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelFinal)

(exp(coef(modelFinal)) - 1) * 100

hist(resid(modelFinal))
range(exp(predict(modelFinal)))
plot(log(BigDays.sfdfT$nT), predict(modelFinal))
cor.test(BigDays.sfdfT$nT, predict(modelFinal, type = "response"))
mean(abs(BigDays.sfdfT$nT - predict(modelFinal, type = "response")))
mean(abs(BigDays.sfdfT$nT - predict(modelFinal, type = "response")))/(max(BigDays.sfdfT$nT) - min(BigDays.sfdfT$nT))
mean(abs(BigDays.sfdfT$nT - predict(modelFinal, type = "response")))/(max(predict(modelFinal, type = "response")) - min(predict(modelFinal, type = "response")))

modelglmer.nb <- glmer.nb(nT ~ scale(A) + scale(CAPE) + scale(DLBS) + scale(SLBS) + (1|Month), data = BigDays.sfdfT)
summary(modelglmer.nb) # mixed effects model does not improve things
```

## Observed versus predicted plot
```{r}
df <- data.frame(Observed = BigDays.sfdfT$nT,
                 Predicted = predict(modelFinal, type = "response"))

ggplot(df, aes(x = Observed, y = Predicted)) +
  geom_abline() +
  geom_point(col = "gray70") +
  geom_smooth(method = lm, size = 1, col = "black") +
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal() 
```

## Casualty model
```{r}
modelInitialC <- glm.nb(GroupDayCas ~ P + Lat + Lon + Year + CAPE + CIN + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelInitialC)

modelFinalC <- glm.nb(GroupDayCas ~ P + Lat + Lon + Year + CAPE + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelFinalC)

hist(resid(modelFinalC))
range(exp(predict(modelFinalC)))
plot(log(BigDays.sfdfT$GroupDayCas), predict(modelFinalC))
cor.test(BigDays.sfdfT$GroupDayCas, exp(predict(modelFinalC)))

mean(abs(BigDays.sfdfT$GroupDayCas - predict(modelFinalC, type = "response")))
mean(abs(BigDays.sfdfT$GroupDayCas - predict(modelFinalC, type = "response")))/(max(BigDays.sfdfT$GroupDayCas) - min(BigDays.sfdfT$GroupDayCas))
mean(abs(BigDays.sfdfT$GroupDayCas - predict(modelFinalC, type = "response")))/(max(predict(modelFinalC, type = "response")) - min(predict(modelFinalC, type = "response")))
```

## Observed versus predicted plot
```{r}
df <- data.frame(Observed = BigDays.sfdfT$GroupDayCas,
                 Predicted = predict(modelFinalC, type = "response"))

ggplot(df, aes(x = Observed +.54, y = Predicted)) +
  geom_abline() +
  geom_point(col = "gray70") +
  geom_smooth(method = lm, size = 1, col = "black") +
  xlab("Observed") +
  scale_x_log10() +
  scale_y_log10() +
  theme_minimal() 
```

## Cross validation
```{r}
formulaT <- nT ~ A + CAPE + DLBS + SLBS
formulaC <- GroupDayCas ~ P + Lat + Lon + Year + CAPE + DLBS + SLBS #+ nT
modelFinalT <- glm.nb(formulaT, data = BigDays.sfdfT)
modelFinalC <- glm.nb(formulaC, data = BigDays.sfdfT)

TCount <- numeric()
CCount <- numeric()

for(i in 1:nrow(BigDays.sfdfT)){
TCount[i] <- predict(glm.nb(formulaT, data = BigDays.sfdfT[-i, ]), 
                       newdata = BigDays.sfdfT[i,],
                       type = "response")
CCount[i] <- predict(glm.nb(formulaC, data = BigDays.sfdfT[-i, ]), 
                       newdata = BigDays.sfdfT[i,],
                       type = "response")
}
cor(BigDays.sfdfT$nT, TCount)
cor(BigDays.sfdfT$GroupDayCas, CCount)

mean(abs(BigDays.sfdfT$nT - TCount))
mean(abs(BigDays.sfdfT$nT - TCount))/(max(BigDays.sfdfT$nT) - min(BigDays.sfdfT$nT))
mean(abs(BigDays.sfdfT$nT - predict(modelFinalT, type = "response")))/(max(predict(modelFinalT, type = "response")) - min(predict(modelFinalT, type = "response")))

mean(abs(BigDays.sfdfT$GroupDayCas - CCount))
mean(abs(BigDays.sfdfT$GroupDayCas - CCount))/(max(BigDays.sfdfT$GroupDayCas) - min(BigDays.sfdfT$GroupDayCas))
mean(abs(BigDays.sfdfT$GroupDayCas - predict(modelFinalC, type = "response")))/(max(predict(modelFinalC, type = "response")) - min(predict(modelFinalC, type = "response")))
```

## Under/over predictions
```{r}
df <- data.frame(Observed = BigDays.sfdfT$GroupDayCas,
                 Predicted = CCount) %>%
  mutate(Diff = Observed - Predicted)
```

## Tornado predictions 1-D
```{r}
theta <- 6.246
nTthresh <- 20
predict(modelFinal, newdata = data.frame(A = c(mean(BigDays.sfdfT$A), mean(BigDays.sfdfT$A)),
                                         CAPE = c(0, 5),
                                         DLBS = c(mean(BigDays.sfdfT$DLBS), mean(BigDays.sfdfT$DLBS)),
                                         SLBS = c(mean(BigDays.sfdfT$SLBS), mean(BigDays.sfdfT$SLBS))),
        type = "response")

1 - pnbinom(nTthresh, size = theta, mu = 18.725) # chance that the outbreak will have more than 50 tornadoes when CAPE = 0
1 - pnbinom(nTthresh, size = theta, mu = 23.55)  # chance that the outbreak will have more than 50 tornadoes when CAPE = 5000

predictions  <- predict(modelFinal, 
                        newdata = data.frame(A = rep(mean(BigDays.sfdfT$A), times = 6),
                                             CAPE = 0:5,
                                             DLBS = rep(mean(BigDays.sfdfT$DLBS), times = 6),
                                             SLBS = rep(mean(BigDays.sfdfT$SLBS), times = 6)),
                        type = "response")
```

```{r}
( CAPElevels <- round(quantile(BigDays.sfdfT$maxCAPE, probs = c(.05, .5, .95))) )
CAPElevels <- c(100, 2000, 5000)
theta <- 6.246
nTthresh <- 30
Area <- 40 # Area of 10\% tor probability April 12, 2020 outbreak 12UTC

predictions  <- predict(modelFinal, 
                        newdata = data.frame(A = Area,
                                             CAPE = CAPElevels[1]/1000,
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)
plot.predictions <- data.frame(CAPE = CAPElevels[1],
                               probability = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)

predictions  <- predict(modelFinal, 
                        newdata = data.frame(A = Area,
                                             CAPE = CAPElevels[2]/1000,
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions2 <- data.frame(CAPE = CAPElevels[2],
                               probability = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)

predictions  <- predict(modelFinal, 
                        newdata = data.frame(A = Area,
                                             CAPE = CAPElevels[3]/1000,
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions3 <- data.frame(CAPE = CAPElevels[3],
                               probability = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nTthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)


plot.predictions <- rbind(plot.predictions, plot.predictions2, plot.predictions3)


library(ggplot2)
ggplot(plot.predictions, aes(x = DLBS,
                             y = probability, 
                             color = factor(CAPE, levels = rev(CAPElevels)),
                             group = factor(CAPE, levels = rev(CAPElevels)))) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymin = probabilityL, ymax = probabilityU), color = NA, fill = "gray80", alpha = .2) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  scale_colour_ordinal(name = "CAPE (J/kg)", direction = -1, alpha = .6) +
  ylab(paste("Probability of at least", nTthresh, "tornadoes")) +
  xlab("Deep-layer bulk shear (m/s)") +
  theme_minimal()
```

## Tornado predictions 2-D
```{r}
library(directlabels)

pgrid <- expand.grid(CAPE = seq(1, 5, .05),
                     DLBS = seq(1, 4, .05),
                     A = Area,
                     SLBS = mean(BigDays.sfdfT$SLBS))

predictions <- predict.glm(modelFinal, newdata = pgrid, type = "response")
pgrid$probability <-1 - pnbinom(nTthresh, size = theta, mu = predictions)

( p <- ggplot(pgrid, aes(x = CAPE * 1000, y = DLBS * 10, fill = probability)) +
          geom_raster() +
          scale_fill_viridis_c(alpha = .6) +
          geom_contour(aes(color = ..level.., z = probability), breaks = seq(.3, .6, by = .1), color = "black") +
          ylab("Deep-layer bulk shear (m/s)") +
          xlab("CAPE (J/kg)") + 
          theme_minimal() )
#    ggtitle("Probability of at least 30 tornadoes in an outbreak")
direct.label(p, list("angled.boxes"))
```

## Casualty predictions 1-D

Start with shear (DLBS)
```{r}
( Plevels <- c(10, 40, 80) ) # 100,000s
theta <- .261
nCthresh <- 50 # arbitrary threshold number of casualties

predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[1],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = mean(BigDays.sfdfT$CAPE),
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)
plot.predictions <- data.frame(P = Plevels[1],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)

predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[2],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = mean(BigDays.sfdfT$CAPE),
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions2 <- data.frame(P = Plevels[2],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)

predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[3],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = mean(BigDays.sfdfT$CAPE),
                                             DLBS = seq(1, 4, by = .25),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions3 <- data.frame(P = Plevels[3],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               DLBS = seq(1, 4, by = .25) * 10)


plot.predictions <- rbind(plot.predictions, plot.predictions2, plot.predictions3)

cbPalette <- c("#E69F00", "#56B4E9", "#009E73")
(p1 <- ggplot(plot.predictions, aes(x = DLBS, 
                                    y = probability, 
                                    color = factor(P * 100000, levels = rev(Plevels * 100000)),
                                    group = factor(P * 100000, levels = rev(Plevels * 100000)))) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymin = probabilityL, ymax = probabilityU), color = NA, fill = "gray80", alpha = .2) +
  scale_y_continuous(limits = c(0, .3), labels = scales::percent) +
  scale_colour_manual(name = "Population", labels = c("8M", "4M", "1M"), values = cbPalette) + 
  ylab(paste("Probability of at least", nCthresh, "casualties")) +
  xlab("Deep-layer bulk shear (m/s)") +
  theme_minimal() )
```

Repeat for with CAPE
```{r}
( Plevels <- c(10, 40, 80) ) # 100,000s
theta <- .261
nCthresh <- 50 # arbitrary threshold number of casualties
predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[1],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = seq(0, 5, by = .25),
                                             DLBS = mean(BigDays.sfdfT$DLBS),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)
plot.predictions <- data.frame(P = Plevels[1],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               CAPE = seq(0, 5, by = .25) * 1000)

predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[2],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = seq(0, 5, by = .25),
                                             DLBS = mean(BigDays.sfdfT$DLBS),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions2 <- data.frame(P = Plevels[2],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               CAPE = seq(0, 5, by = .25) * 1000)

predictions  <- predict(modelFinalC, 
                        newdata = data.frame(P = Plevels[3],
                                             Lat = mean(BigDays.sfdfT$Lat),
                                             Lon = mean(BigDays.sfdfT$Lon),
                                             Year = 2018,
                                             CAPE = seq(0, 5, by = .25),
                                             DLBS = mean(BigDays.sfdfT$DLBS),
                                             SLBS = mean(BigDays.sfdfT$SLBS)),
                        type = "response",
                        se.fit = TRUE)

plot.predictions3 <- data.frame(P = Plevels[3],
                               probability = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit),
                               probabilityU = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit + 1 * predictions$se.fit),
                               probabilityL = 1 - pnbinom(nCthresh, size = theta, mu = predictions$fit - 1 * predictions$se.fit),
                               CAPE = seq(0, 5, by = .25) * 1000)


plot.predictions <- rbind(plot.predictions, plot.predictions2, plot.predictions3)

( p2 <- ggplot(plot.predictions, aes(x = CAPE, 
                                     y = probability, 
                                     color = factor(P * 100000, levels = rev(Plevels * 100000)),
                                     group = factor(P * 100000, levels = rev(Plevels * 100000)))) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymin = probabilityL, ymax = probabilityU), color = NA, fill = "gray80", alpha = .2) +
  scale_y_continuous(limits = c(0, .3), labels = scales::percent) +
   scale_colour_manual(name = "Population", labels = c("8M", "4M", "1M"), values = cbPalette) + 
  ylab(paste("Probability of at least", nCthresh, "casualties")) +
  xlab("CAPE (J/kg)") +
  theme_minimal() )

library(patchwork)

p1 + p2
```

## Casualty predictions 2-D
```{r}
theta <- modelFinalC$theta
nCthresh <- 25

pgrid1 <- expand.grid(CAPE = seq(1, 5, .05),
                     DLBS = seq(1, 4, .05),
                     SLBS = mean(BigDays.sfdfT$SLBS),
                     P = 40, # 4 million
                     Year = 2018,
                     Lat = 42.5, # Sioux City IA and Birmingham AL
                     Lon = -96.4,
                     Location = "Sioux City, IA") 
pgrid2 <- expand.grid(CAPE = seq(1, 5, .05),
                     DLBS = seq(1, 4, .05),
                     SLBS = mean(BigDays.sfdfT$SLBS),
                     P = 40, # 4 million
                     Year = 2018,
                     Lat = 33.5,
                     Lon = -86.8,
                     Location = "Birmingham, AL") 
pgrid <- rbind(pgrid1, pgrid2)


predictions <- predict.glm(modelFinalC, newdata = pgrid, type = "response")
pgrid$probability <- 1 - pnbinom(nCthresh, size = theta, mu = predictions)

ggplot(pgrid, aes(x = CAPE * 1000, y = DLBS * 10, fill = probability)) +
          geom_raster(alpha = .8) +
          scale_fill_gradientn(colours = rev(cbPalette), name = "Probability", labels = scales::percent) +
          facet_wrap(~ Location) + 
          ylab("Deep-layer bulk shear (m/s)") +
          xlab("CAPE (J/kg)") + 
          theme_minimal()
```

Percentage point differences
```{r}
pgrid1 <- expand.grid(CAPE = seq(1, 5, .05),
                     DLBS = seq(1, 4, .05),
                     SLBS = mean(BigDays.sfdfT$SLBS),
                     P = 40, # 4 million
                     Year = 2018,
                     Lat = 42.5, # Sioux Falls IA 
                     Lon = -96.4) 
predictions <- predict.glm(modelFinalC, newdata = pgrid1, type = "response")
probs1 <- 1 - pnbinom(nCthresh, size = theta, mu = predictions)
pgrid1$probability <- probs1

pgrid2 <- expand.grid(CAPE = seq(1, 5, .05),
                     DLBS = seq(1, 4, .05),
                     SLBS = mean(BigDays.sfdfT$SLBS),
                     P = 40, # 4 million
                     Year = 2018,
                     Lat = 33.5, #Birmingham AL
                     Lon = -86.8) 
predictions <- predict.glm(modelFinalC, newdata = pgrid2, type = "response")
probs2 <- 1 - pnbinom(nCthresh, size = theta, mu = predictions)

pgrid1$ppDiff <- (probs2 - probs1) * 100

( p <- ggplot(pgrid1, aes(x = CAPE * 1000, y = DLBS * 10, fill = probability)) +
          geom_raster() +
          scale_fill_gradientn(colours = rev(cbPalette)) +
 #         geom_contour(aes(color = ..level.., z = ppDiff), breaks = seq(2, 12, by = 2), color = "black") +
          ylab("Deep-layer bulk shear (m/s)") +
          xlab("CAPE (J/kg)") + 
          theme_minimal() )
direct.label(p, list("angled.boxes"))
```

## April 12, 2020 case https://www.spc.noaa.gov/cgi-bin-spc/getacrange.pl?date0=20200412&date1=20200412
```{r}
library(sf)

read_sf(dsn = "day1otlk_20200412_1200-shp",
                         layer = "day1otlk_20200412_1200_torn") %>%
  st_transform(crs = 3857) %>%
  st_area()

quantile(BigDays.sfdfT$HullArea)
```

## Trends
```{r}
BigDays.sfdfT %>%
#  filter(Mo %in% c(3, 4, 5, 6)) %>%
  group_by(Year) %>%
  summarize(Avg = mean(SLBS)) %>%
ggplot(aes(x = Year, y = Avg)) +
  geom_point() +
  geom_smooth(method = lm)
```

